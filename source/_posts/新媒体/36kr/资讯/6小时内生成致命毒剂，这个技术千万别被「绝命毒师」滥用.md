
---
title: '6小时内生成致命毒剂，这个技术千万别被「绝命毒师」滥用'
categories: 
 - 新媒体
 - 36kr
 - 资讯
headimg: 'https://img.36krcdn.com/20220319/v2_7e033b27723e4e9d8a7a52e635d2f62d_img_000'
author: 36kr
comments: false
date: Mon, 21 Mar 2022 01:06:54 GMT
thumbnail: 'https://img.36krcdn.com/20220319/v2_7e033b27723e4e9d8a7a52e635d2f62d_img_000'
---

<div>   
<p>几天前有这样一则新闻：济南市公安局成功捣毁一冰毒制造场，制毒嫌疑人李某从 2021 年开始在网上学习制毒知识，为系统学习化学专业知识还花钱在济南一所大学旁听。《绝命毒师》的主角 Walter White 也是一名化学老师。 </p> 
<p>不少人都觉得，制毒也并不是件容易的事，至少需要掌握相关的知识。但如果，用人工智能就能实现呢？而且 AI 系统「造」出的不是毒品而是毒剂。 </p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220319/v2_7e033b27723e4e9d8a7a52e635d2f62d_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>《绝命毒师》剧照，图片来自：豆瓣 </p> 
<p>在以 Fabio Urbina 为第一作者发表在《Nature Machine Intelligence》杂志上的一篇论文里提到，Urbina 所在的公司 Collaborations Pharmaceuticals，最近公布了用于预测毒性的计算机机器学习模型。 </p> 
<p>公司受邀参加由瑞士 NBC（核、生物和化学）保护研究所召开的会议，讨论尖端化学和生物技术可能产生影响的工具的新发展，Collaborations Pharmaceuticals 受邀谈论关于人工智能技术可能被滥用的问题。 </p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220319/v2_e53063482d9843699fe971ddd100b494_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>图片来自：Collaborations Pharmaceuticals </p> 
<p>Urbina 表示，在这之前似乎没有想过相关的问题。因为几十年间，他们的工作是建立机器学习模型来发现可用于药物的新分子，使用计算机和人工智能是用来改善人类健康，而不是破坏它。 </p> 
<p>在瑞士的会议上，Collaborations Pharmaceuticals 公司却决定探索如何使用 AI <a class="project-link" data-id="109619" data-name="来设计" data-logo="https://img.36krcdn.com/20210808/v2_9a43df76eb32401dbacc1653730bfa54_img_000" data-refer-type="2" href="https://36kr.com/projectDetails/109619" target="_blank">来设计</a>有毒分子。该公司之前设计了一种名为 MegaSyn 的商业 de novo 分子生成模型，借助机器学习模型预测生物活性，寻找人类疾病靶点的新治疗抑制剂。 </p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220319/v2_b9b9b5ff82b141628a742050bee85ead_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>图片来自：Collaborations Pharmaceuticals </p> 
<p>这种生成模型通常会惩罚预测的毒性并奖励预测的目标活动。之后他们进行了调整，指导模型同时奖励毒性和生物活性，并使用来自公共数据库的分子对人工智能进行训练。 </p> 
<p>调整后的底层生成软件建立在易获得的开源软件上，为了缩小分子的范围，他们选择将生成模型推向诸如神经毒剂 VX 之类的化合物。 </p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220319/v2_f064561e2c6b4015a0a6367af8fa3d57_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>图片来自：美联社 </p> 
<p>VX 是归类为神经毒剂的一种人造化学战剂（化学战剂：用于战争目的、具有剧烈毒性、能大规模地毒害或杀伤敌方人畜和植物的各种化学物质），毒性强且作用迅速，6-10 毫克的 VX 颗粒便足以致命。 </p> 
<p>在内部服务器上启动后的 6 小时内，新的模型就生成了 40000 个分子。在这当中，人工智能不仅设计出了 VX，还设计了许多其他已知的化学战剂。出乎意料的是，它还设计出了许多看起来同样合理的新分子，根据预测值来看，这些新分子被预测比已知的化学战剂毒性更大。 </p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220319/v2_7b49743dd80e49129d0f153948354d97_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>图片来自：Nature </p> 
<p>在他们用于训练 AI 的数据集里，并不包括这些神经毒剂。但通过反转机器学习模型的使用方式，却将无害的生成模型从有用的医学工具转变为可能致命的分子生成器。 </p> 
<p>为了避免毒性而创建的模型，成了「双刃剑」。从事研究的人员越能预测毒性，引导生成模型在一个主要由致命分子组成的化学空间里设计新分子的效果也越强。 </p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220319/v2_1c1809a1641f49ebaa83f62bacf4b359_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>图片来自：Unsplash </p> 
<p>其实，Collaborations Pharmaceuticals 公司并没有评估模型生成的虚拟分子的可合成性，也没有探索如何制造它们。但对于这两个过程，都有现成的商业模式和开源软件。虽然他们也没有物理合成任何分子，但全球范围内有数百家商业公司可以提供化学合成。 </p> 
<p>他们的探索，证明一件事：非人类的自主创造者也可以制造致命化学武器。 </p> 
<p>虽然目前要生成可能造成重大伤害的有毒物质或生物制剂仍然需要一些化学或毒理学领域的专业知识，但加入机器学习模型后，技术门槛就会大大降低，需要的可能只是编码和理解模型输出的能力。 </p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220319/v2_bf0c582c694b4ffb85fdae56f048b497_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>图片来自：Unsplash </p> 
<p>商业工具，开源软件工具和公共数据库中的许多数据集，都可以在没有监督的情况下使用，利用人工智能生成有害分子的模型似乎成了一个被打开的「魔盒」。生成的这些分子可以被轻松抹去，但如何创造它们的知识却不会消失。 </p> 
<p>很明显，必须要想办法避免这种对人工智能的滥用。Urbina 认为，人工智能驱动的化学战并不会很快出现，但存在这种可能。 </p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220319/v2_2cac02393f7f4096a90b37c3eb212c8e_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>图片来自：Unsplash </p> 
<p>公司的 MegaSyn 是商业产品，他们可控制谁可以访问它，未来也可能会对模型实施限制。像硅谷的 OpenAI 组织的「 GPT-3 」语言模型那样，虽然可以随时免费使用它，但他们随时可以切断用户对这些模型的访问。 </p> 
<p class="image-wrapper"><img data-img-size-val src="https://img.36krcdn.com/20220319/v2_36c3aa9bedba42f5b1a6d417b9c45c7d_img_000" referrerpolicy="no-referrer"></p> 
<p label="图片描述" classname="img-desc" class="img-desc" style>图片来自：Synced </p> 
<p>Urbina 还提到，大学也要加倍努力对理科学生进行道德培训，并将范围扩大到其他学科，尤其是计算机专业的学生，让他们能意识到人工智能滥用的可能性。 </p> 
<p>这项探索似乎再次印证了人们总说的那句话：技术无罪，造福还是作恶，取决于使用者的目的。 </p> 
<p>本文来自<a class="project-link" data-id="3968527" data-name="微信" data-logo="https://img.36krcdn.com/20200916/v2_811751a081924fa9af8741ce120bd7bf_img_png" data-refer-type="2" href="https://36kr.com/projectDetails/3968527" target="_blank">微信</a>公众号 <a target="_blank" rel="noopener noreferrer nofollow" href="http://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&mid=2652082645&idx=2&sn=1d35149971db70737c76c98e17560e85&chksm=9b65074aac128e5c6b0c0eb039b1e6e4d8c98fcde94f3373039ca03577bb91e13aaa49000949#rd">“爱范儿”（ID：ifanr）</a>，作者：邓南，36氪经授权发布。</p>  
</div>
            